{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d1ea747-5ff9-47c9-8889-0dba8a3fbdac",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0c4e55-4bdc-459c-bc01-3baff7468664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d820e2f-3e1c-4517-a9b3-a7ab87512a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing the randomness\n",
    "import random\n",
    "random.seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bde271-2a5f-479a-a63c-2664338760b2",
   "metadata": {},
   "source": [
    "To start, we will create our data. We are looking at the random forest classifier, so we'll use the diabetes dataset, used for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "249d0e10-001f-4b6b-a6db-016d63474406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# Import the diabetes dataset from sklearn\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "# load the dataset\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38c2e520-478f-45da-8bf8-5c701b0688df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    cancer.data, cancer.target,  test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92daa85-f23e-48cd-b3c7-3118c0a224c4",
   "metadata": {},
   "source": [
    "Creating a Random Forest classifier with sk-learn is not different than using other type of classifier, such as the Decision Tree we saw last time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b93aaa6d-95c3-43db-bb53-e115e5435faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the random forest classifier algorithm function from sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# the random forest is stochastic, so we use a random_state parameter to fix the result\n",
    "clf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1accfc51-d4ee-41d7-9538-db20e2df82ec",
   "metadata": {},
   "source": [
    "And we use the same method for training than we usually do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c79c3659-1fae-4d05-a816-3d885cd8f94b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9707602339181286"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48bc05f-3f0a-43e0-aa7e-7e33eb7455c6",
   "metadata": {},
   "source": [
    "## Part II\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b4ea04-b995-4eb0-a589-d97fdb831051",
   "metadata": {},
   "source": [
    "The `max_features` parameter can be set manually with an integer for an hard value or a float for percentage, or you can use some preset value such as `'sqrt'` which consider $\\sqrt{N}$ features for each split, with $N$ being the number of features. \n",
    "\n",
    "The square root is the default parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6564cdf9-0134-48e5-a15a-10e984939c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = RandomForestClassifier(max_features=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "099d25a1-51c7-4fb7-9d93-1093515eb48d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9766081871345029"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2.fit(x_train, y_train)\n",
    "clf2.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe38a4e-7709-40e7-b080-af10078ae780",
   "metadata": {},
   "source": [
    "By default the `max_depth` parameter doesn't have any value, and such the nodes are expanded until the leaves are pure (or until other hyper-parameter such as `min_samples_split` decides it).\n",
    "\n",
    "The sk-learn user mention this:\n",
    "> Good results are often achieved when setting `max_depth=None` in combination with `min_samples_split=2` (i.e., when fully developing the trees).\n",
    "\n",
    "However, you can still set a maximum depth by hand, with an integer. Doing so will help reducing the size of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cde1d972-2dd5-4552-b28d-cf263d985b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 = RandomForestClassifier(max_depth=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d11a3ad-4a46-4cf7-b7ab-3654644e852c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9590643274853801"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf3.fit(x_train, y_train)\n",
    "clf3.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ed23b7d-4045-40c7-8280-db66433e53c8",
   "metadata": {},
   "source": [
    "The number of trees is also an important parameter. You can changed it with the `n_estimators` argument. \n",
    "\n",
    "User guide:\n",
    "> The larger the better, but also the longer it will take to compute. In addition, note that results will stop getting significantly better beyond a critical number of trees. \n",
    "\n",
    "The default value is 100, but you can change it for another integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40d53357-6d36-4e58-8fe6-d590d1bfe858",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf4 = RandomForestClassifier(n_estimators=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "02c17c96-55a5-49e0-89f7-9e4d8b01863e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9649122807017544"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf4.fit(x_train, y_train)\n",
    "clf4.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bdcd83fb-75e8-43a8-a18b-f7164fbcf5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf5 = RandomForestClassifier(n_estimators=1000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "215dc4fc-321a-4399-9b44-830fc63b103f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9707602339181286"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf5.fit(x_train, y_train)\n",
    "clf5.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0781615-3f90-42a1-bb5a-ce2eaff3bcc1",
   "metadata": {},
   "source": [
    "You can decide to use bootstrapping or the entire dataset for each tree with the `bootstrap` argument. The default value is `True`. \n",
    "\n",
    "If it is `True`, you can control the size of the bagging with the `max_samples` argument. By default it is `None`, which draws all the sample. You can change it to an int or a float for percentage. \n",
    "\n",
    "User guide:\n",
    "> A typical value of subsample is 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea75561f-6b06-4b47-a909-70285e705aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf6 = RandomForestClassifier(max_samples=1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "142c2749-0065-42b7-ba01-430329bb827f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.631578947368421"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf6.fit(x_train, y_train)\n",
    "clf6.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4eeff9d8-7856-4453-9dc1-81d324b3178a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7 = RandomForestClassifier(max_samples=0.4, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c18609e8-d7a9-4cb9-bbf1-3e2c8ac5907e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9707602339181286"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf7.fit(x_train, y_train)\n",
    "clf7.score(x_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
